# å·¥ç¨‹è´¨é‡æ‰‹å†Œ (Engineering Quality Handbook)

**ç‰ˆæœ¬**: 1.0.0  
**æ›´æ–°æ—¥æœŸ**: 2025-01-29  
**é€‚ç”¨é¡¹ç›®**: GreenLink Capital - Enterprise Green Asset Management Platform  
**æŠ€æœ¯æ ˆ**: Next.js 15 + FastAPI + Docker + GitHub Actions

---

## ğŸ“‹ ç›®å½•

1. [ä»£ç å®¡æŸ¥æµç¨‹ (Code Review Process)](#1-ä»£ç å®¡æŸ¥æµç¨‹-code-review-process)
2. [è‡ªåŠ¨åŒ–æµ‹è¯•è¦†ç›–ç­–ç•¥ (Automated Test Coverage)](#2-è‡ªåŠ¨åŒ–æµ‹è¯•è¦†ç›–ç­–ç•¥-automated-test-coverage)
3. [æ€§èƒ½åŸºå‡†ç›‘æ§ (Performance Baseline Monitoring)](#3-æ€§èƒ½åŸºå‡†ç›‘æ§-performance-baseline-monitoring)
4. [è‡ªåŠ¨åŒ–å®‰å…¨æ‰«æ (Automated Security Scanning)](#4-è‡ªåŠ¨åŒ–å®‰å…¨æ‰«æ-automated-security-scanning)

---

## è´¨é‡ä¿è¯åŸåˆ™

### æ ¸å¿ƒç†å¿µ
> **"è´¨é‡å†…å»ºï¼Œå·¦ç§»ä¸ºå…ˆï¼Œè‡ªåŠ¨åŒ–ä¼˜å…ˆï¼ŒæŒç»­æ”¹è¿›"**

### å››å¤§æ”¯æŸ±
- ğŸ” **ä»£ç å®¡æŸ¥**: äººæ–‡åä½œä¿è¯ä»£ç è´¨é‡
- ğŸ§ª **æµ‹è¯•è¦†ç›–**: è‡ªåŠ¨åŒ–éªŒè¯åŠŸèƒ½æ­£ç¡®æ€§
- âš¡ **æ€§èƒ½ç›‘æ§**: æŒç»­ä¿è¯ç”¨æˆ·ä½“éªŒè´¨é‡
- ğŸ›¡ï¸ **å®‰å…¨æ‰«æ**: å·¦ç§»å®‰å…¨ï¼Œé˜²æ‚£äºæœªç„¶

---

## 1. ä»£ç å®¡æŸ¥æµç¨‹ (Code Review Process)

### 1.1 Pull Request ç”Ÿå‘½å‘¨æœŸ

```mermaid
graph LR
    A[Draft PR] --> B[Ready for Review]
    B --> C[Code Review]
    C --> D{Review Result}
    D -->|Changes Requested| E[Address Feedback]
    E --> C
    D -->|Approved| F[Merge to Main]
    F --> G[Deployment Pipeline]
```

#### çŠ¶æ€å®šä¹‰
| çŠ¶æ€ | æè¿° | è¦æ±‚ | è´£ä»»äºº |
|------|------|------|--------|
| **Draft** | å¼€å‘ä¸­ï¼Œæœªå®Œæˆ | WIPæ ‡è®°ï¼ŒCIå¯é€‰ | ä½œè€… |
| **Ready for Review** | å·²å®Œæˆï¼Œç­‰å¾…å®¡æŸ¥ | é€šè¿‡æ‰€æœ‰CIæ£€æŸ¥ | ä½œè€… |
| **In Review** | å®¡æŸ¥è¿›è¡Œä¸­ | è‡³å°‘1ä½å®¡æŸ¥è€…å¼€å§‹review | å®¡æŸ¥è€… |
| **Changes Requested** | éœ€è¦ä¿®æ”¹ | ä½œè€…éœ€è¦addressedæ‰€æœ‰comments | ä½œè€… |
| **Approved** | å®¡æŸ¥é€šè¿‡ | æ»¡è¶³åˆå¹¶æ¡ä»¶ | å®¡æŸ¥è€… |
| **Merged** | å·²åˆå¹¶åˆ°ä¸»åˆ†æ”¯ | è‡ªåŠ¨éƒ¨ç½²è§¦å‘ | ç³»ç»Ÿ |

#### åˆå¹¶è¦æ±‚
- âœ… **è‡³å°‘2ä½åŒäº‹çš„Approve** (å¯¹äºæ ¸å¿ƒåŠŸèƒ½)
- âœ… **æ‰€æœ‰CIæ£€æŸ¥é€šè¿‡** (æµ‹è¯•ã€æ„å»ºã€å®‰å…¨æ‰«æ)
- âœ… **æ— æœªè§£å†³çš„Change Request**
- âœ… **åˆ†æ”¯ä¸mainåˆ†æ”¯ä¿æŒåŒæ­¥**

### 1.2 Pull Request æ¨¡æ¿

åˆ›å»º `.github/pull_request_template.md` æ–‡ä»¶ï¼š

```markdown
## Pull Request æè¿°

### ğŸ¯ åšäº†ä»€ä¹ˆ (What)
<!-- ç®€æ´æè¿°æœ¬æ¬¡PRçš„ä¸»è¦å˜æ›´å†…å®¹ -->

### ğŸ¤” ä¸ºä»€ä¹ˆè¿™ä¹ˆåš (Why)
<!-- è§£é‡Šå˜æ›´çš„ä¸šåŠ¡åŸå› æˆ–æŠ€æœ¯åŠ¨æœº -->

### ğŸ”§ å¦‚ä½•å®ç° (How)
<!-- ç®€è¿°å®ç°æ€è·¯å’Œå…³é”®æŠ€æœ¯å†³ç­– -->

---

## ğŸš¦ æäº¤å‰è‡ªæ£€æ¸…å• (Author Checklist)

ä½œè€…åœ¨æäº¤PRå‰å¿…é¡»ç¡®è®¤ï¼š

- [ ] **ä»£ç è´¨é‡**
  - [ ] å·²å®Œæˆè‡ªæˆ‘ä»£ç review
  - [ ] ä»£ç ç¬¦åˆå›¢é˜Ÿç¼–ç è§„èŒƒ
  - [ ] ç§»é™¤äº†è°ƒè¯•ä»£ç å’Œæ— ç”¨æ³¨é‡Š
  - [ ] å˜é‡å’Œå‡½æ•°å‘½åæ¸…æ™°æ˜ç¡®

- [ ] **åŠŸèƒ½éªŒè¯**
  - [ ] æœ¬åœ°åŠŸèƒ½æµ‹è¯•é€šè¿‡
  - [ ] è¦†ç›–äº†ä¸»è¦ç”¨æˆ·åœºæ™¯
  - [ ] è¾¹ç•Œæ¡ä»¶å¤„ç†æ­£ç¡®
  - [ ] é”™è¯¯å¤„ç†å’Œç”¨æˆ·åé¦ˆå®Œå–„

- [ ] **æµ‹è¯•è¦†ç›–**
  - [ ] æ–°å¢åŠŸèƒ½æœ‰å¯¹åº”å•å…ƒæµ‹è¯•
  - [ ] å¤æ‚é€»è¾‘æœ‰é›†æˆæµ‹è¯•
  - [ ] æœ¬åœ°æ‰€æœ‰æµ‹è¯•é€šè¿‡
  - [ ] æµ‹è¯•è¦†ç›–ç‡æ»¡è¶³è¦æ±‚(â‰¥80%)

- [ ] **æ€§èƒ½ä¸å®‰å…¨**
  - [ ] æ— æ˜æ˜¾æ€§èƒ½é—®é¢˜
  - [ ] æ— æ–°å¢å®‰å…¨æ¼æ´
  - [ ] APIå“åº”æ—¶é—´åœ¨åˆç†èŒƒå›´
  - [ ] å‰ç«¯åŒ…å¤§å°æ— å¼‚å¸¸å¢é•¿

- [ ] **æ–‡æ¡£æ›´æ–°**
  - [ ] APIå˜æ›´æ›´æ–°äº†å¯¹åº”æ–‡æ¡£
  - [ ] æ–°åŠŸèƒ½æ·»åŠ äº†ä½¿ç”¨è¯´æ˜
  - [ ] README.mdä¿æŒæœ€æ–°
  - [ ] é…ç½®å˜æ›´æœ‰è¯´æ˜æ–‡æ¡£

## ğŸ”— ç›¸å…³é“¾æ¥

- å…³è”Issue: Closes #xxx
- è®¾è®¡æ–‡æ¡£: [é“¾æ¥]
- æµ‹è¯•æŠ¥å‘Š: [é“¾æ¥]
- éƒ¨ç½²è¯´æ˜: [é“¾æ¥]

## ğŸ“¸ Screenshots (å¦‚é€‚ç”¨)
<!-- å¯¹äºUIå˜æ›´ï¼Œè¯·æä¾›å‰åå¯¹æ¯”æˆªå›¾ -->

## ğŸ§ª æµ‹è¯•è¯´æ˜
<!-- æè¿°å¦‚ä½•æµ‹è¯•æœ¬æ¬¡å˜æ›´ï¼ŒåŒ…æ‹¬æµ‹è¯•æ•°æ®å’Œæ­¥éª¤ -->

## âš ï¸ é£é™©è¯„ä¼°
<!-- æè¿°æ½œåœ¨é£é™©å’Œç¼“è§£æªæ–½ -->
- [ ] æ— é£é™©
- [ ] ä½é£é™©: [è¯´æ˜]
- [ ] ä¸­é£é™©: [è¯´æ˜å’Œç¼“è§£æªæ–½]
- [ ] é«˜é£é™©: [è¯¦ç»†åˆ†æå’Œåº”æ€¥æ–¹æ¡ˆ]

## ğŸ“ˆ å½±å“èŒƒå›´
- [ ] ä»…å½±å“æ–°åŠŸèƒ½
- [ ] å½±å“ç°æœ‰åŠŸèƒ½: [å…·ä½“è¯´æ˜]
- [ ] æ•°æ®åº“ç»“æ„å˜æ›´
- [ ] APIæ¥å£å˜æ›´
- [ ] é…ç½®æ–‡ä»¶å˜æ›´
```

### 1.3 å®¡æŸ¥è€…èŒè´£ä¸æ¸…å•

#### å®¡æŸ¥è€…é€‰æ‹©åŸåˆ™
- **ä¸»å®¡æŸ¥è€…**: å¯¹ç›¸å…³æ¨¡å—æœ€ç†Ÿæ‚‰çš„å·¥ç¨‹å¸ˆ
- **æ¬¡å®¡æŸ¥è€…**: ä¸åŒæŠ€æœ¯èƒŒæ™¯çš„å·¥ç¨‹å¸ˆ(ç¡®ä¿å¯ç»´æŠ¤æ€§)
- **é¢†åŸŸä¸“å®¶**: æ¶‰åŠå®‰å…¨ã€æ€§èƒ½ã€æ¶æ„æ—¶éœ€è¦ä¸“å®¶å®¡æŸ¥

#### è¯¦ç»†å®¡æŸ¥æ¸…å• (Reviewer's Checklist)

```markdown
# ä»£ç å®¡æŸ¥æ¸…å• (Code Review Checklist)

## ğŸ—ï¸ æ¶æ„ä¸è®¾è®¡ (Architecture & Design)
- [ ] **æ¶æ„åˆç†æ€§**: ä»£ç ç»“æ„ç¬¦åˆé¡¹ç›®æ¶æ„åŸåˆ™
- [ ] **è®¾è®¡æ¨¡å¼**: åˆç†ä½¿ç”¨è®¾è®¡æ¨¡å¼ï¼Œé¿å…è¿‡åº¦è®¾è®¡
- [ ] **ä¾èµ–ç®¡ç†**: æ–°å¢ä¾èµ–åˆç†ï¼Œé¿å…å¾ªç¯ä¾èµ–
- [ ] **æ¥å£è®¾è®¡**: APIè®¾è®¡ç¬¦åˆRESTfulè§„èŒƒï¼Œå‘åå…¼å®¹
- [ ] **æ•°æ®æ¨¡å‹**: æ•°æ®ç»“æ„è®¾è®¡åˆç†ï¼Œè€ƒè™‘äº†æ‰©å±•æ€§

## ğŸ§¹ ä»£ç è´¨é‡ (Code Quality)
- [ ] **å¯è¯»æ€§**: ä»£ç é€»è¾‘æ¸…æ™°ï¼Œæ˜“äºç†è§£
- [ ] **ç®€æ´æ€§**: æ— é‡å¤ä»£ç ï¼Œå‡½æ•°èŒè´£å•ä¸€
- [ ] **å‘½åè§„èŒƒ**: å˜é‡ã€å‡½æ•°ã€ç±»å‘½åè¯­ä¹‰æ˜ç¡®
- [ ] **æ³¨é‡Šè´¨é‡**: å¤æ‚é€»è¾‘æœ‰é€‚å½“æ³¨é‡Šï¼Œé¿å…è¿‡åº¦æ³¨é‡Š
- [ ] **ä»£ç é£æ ¼**: ç¬¦åˆå›¢é˜Ÿç¼–ç è§„èŒƒ(ESLint/Black)

## ğŸ”§ åŠŸèƒ½å®ç° (Functionality)
- [ ] **éœ€æ±‚å®ç°**: å®Œæ•´å®ç°äº†éœ€æ±‚è§„æ ¼
- [ ] **è¾¹ç•Œæ¡ä»¶**: æ­£ç¡®å¤„ç†è¾¹ç•Œæƒ…å†µå’Œå¼‚å¸¸
- [ ] **é”™è¯¯å¤„ç†**: å¼‚å¸¸å¤„ç†å®Œå–„ï¼Œç”¨æˆ·å‹å¥½çš„é”™è¯¯ä¿¡æ¯
- [ ] **è¾“å…¥éªŒè¯**: å¯¹ç”¨æˆ·è¾“å…¥è¿›è¡Œå……åˆ†éªŒè¯
- [ ] **ä¸šåŠ¡é€»è¾‘**: ä¸šåŠ¡é€»è¾‘æ­£ç¡®ï¼Œç¬¦åˆäº§å“éœ€æ±‚

## ğŸ§ª æµ‹è¯•è¦†ç›– (Test Coverage)
- [ ] **å•å…ƒæµ‹è¯•**: æ ¸å¿ƒé€»è¾‘æœ‰å•å…ƒæµ‹è¯•è¦†ç›–
- [ ] **é›†æˆæµ‹è¯•**: æ¥å£è°ƒç”¨æœ‰é›†æˆæµ‹è¯•
- [ ] **æµ‹è¯•è´¨é‡**: æµ‹è¯•ç”¨ä¾‹å…¨é¢ï¼ŒåŒ…å«æ­£å¸¸å’Œå¼‚å¸¸åœºæ™¯
- [ ] **æµ‹è¯•æ•°æ®**: æµ‹è¯•æ•°æ®åˆç†ï¼Œä¸ä¾èµ–å¤–éƒ¨ç¯å¢ƒ
- [ ] **è¦†ç›–ç‡**: æµ‹è¯•è¦†ç›–ç‡è¾¾æ ‡ (â‰¥80%)

## ğŸ”’ å®‰å…¨æ€§ (Security)
- [ ] **è¾“å…¥å®‰å…¨**: SQLæ³¨å…¥ã€XSSã€CSRFé˜²æŠ¤
- [ ] **æƒé™æ§åˆ¶**: æ­£ç¡®çš„èº«ä»½è®¤è¯å’Œæˆæƒæ£€æŸ¥
- [ ] **æ•æ„Ÿæ•°æ®**: æ•æ„Ÿä¿¡æ¯ä¸åœ¨ä»£ç ä¸­ç¡¬ç¼–ç 
- [ ] **åŠ å¯†ä¼ è¾“**: HTTPSå’Œæ•°æ®åŠ å¯†æ­£ç¡®ä½¿ç”¨
- [ ] **ä¾èµ–å®‰å…¨**: æ— å·²çŸ¥å®‰å…¨æ¼æ´çš„ä¾èµ–

## âš¡ æ€§èƒ½å½±å“ (Performance)
- [ ] **ç®—æ³•æ•ˆç‡**: ç®—æ³•æ—¶é—´å¤æ‚åº¦åˆç†
- [ ] **æ•°æ®åº“æŸ¥è¯¢**: SQLæŸ¥è¯¢ä¼˜åŒ–ï¼Œé¿å…N+1é—®é¢˜
- [ ] **ç¼“å­˜ç­–ç•¥**: åˆç†ä½¿ç”¨ç¼“å­˜ï¼Œé¿å…ç¼“å­˜ç©¿é€
- [ ] **èµ„æºä½¿ç”¨**: å†…å­˜å’ŒCPUä½¿ç”¨åˆç†
- [ ] **å¹¶å‘å¤„ç†**: æ­£ç¡®å¤„ç†å¹¶å‘åœºæ™¯

## ğŸ“± å‰ç«¯ç‰¹å®š (Frontend Specific)
- [ ] **å“åº”å¼è®¾è®¡**: ç§»åŠ¨ç«¯é€‚é…è‰¯å¥½
- [ ] **æ— éšœç¢è®¿é—®**: ç¬¦åˆWCAGå¯è®¿é—®æ€§æ ‡å‡†
- [ ] **æ€§èƒ½ä¼˜åŒ–**: å›¾ç‰‡ä¼˜åŒ–ï¼Œä»£ç åˆ†å‰²ï¼Œæ‡’åŠ è½½
- [ ] **ç”¨æˆ·ä½“éªŒ**: åŠ è½½çŠ¶æ€ï¼Œé”™è¯¯æç¤ºï¼Œäº¤äº’åé¦ˆ
- [ ] **å…¼å®¹æ€§**: æµè§ˆå™¨å…¼å®¹æ€§æµ‹è¯•é€šè¿‡

## ğŸ”™ åç«¯ç‰¹å®š (Backend Specific)  
- [ ] **APIè®¾è®¡**: RESTfulè®¾è®¡ï¼ŒHTTPçŠ¶æ€ç æ­£ç¡®
- [ ] **æ•°æ®ä¸€è‡´æ€§**: äº‹åŠ¡å¤„ç†æ­£ç¡®ï¼Œé¿å…æ•°æ®ç«äº‰
- [ ] **æ‰©å±•æ€§**: æ”¯æŒæ°´å¹³æ‰©å±•ï¼Œæ— çŠ¶æ€è®¾è®¡
- [ ] **ç›‘æ§æ—¥å¿—**: å…³é”®æ“ä½œæœ‰æ—¥å¿—è®°å½•
- [ ] **é”™è¯¯æ¢å¤**: ä¼˜é›…é™çº§å’Œé”™è¯¯æ¢å¤æœºåˆ¶

## ğŸ“š æ–‡æ¡£æ›´æ–° (Documentation)
- [ ] **APIæ–‡æ¡£**: OpenAPIè§„èŒƒæ›´æ–°
- [ ] **README**: ä½¿ç”¨è¯´æ˜å’Œéƒ¨ç½²æŒ‡å—æ›´æ–°
- [ ] **å˜æ›´æ—¥å¿—**: CHANGELOG.mdè®°å½•é‡è¦å˜æ›´
- [ ] **é…ç½®è¯´æ˜**: æ–°å¢é…ç½®é¡¹æœ‰æ–‡æ¡£è¯´æ˜
- [ ] **è¿ç§»æŒ‡å—**: ç ´åæ€§å˜æ›´æœ‰è¿ç§»æŒ‡å—
```

#### å®¡æŸ¥æµç¨‹å’Œæ²Ÿé€šè§„èŒƒ

**ğŸ“ Comment ç±»å‹æ ‡å‡†**:
- `[MUST]`: å¿…é¡»ä¿®æ”¹çš„é—®é¢˜ï¼Œé˜»å¡åˆå¹¶
- `[SHOULD]`: å»ºè®®ä¿®æ”¹ï¼Œæå‡ä»£ç è´¨é‡
- `[QUESTION]`: è¯¢é—®å’Œè®¨è®ºï¼Œéœ€è¦ä½œè€…å›å¤
- `[NITPICK]`: ç»†èŠ‚æ”¹è¿›ï¼Œéé˜»å¡æ€§å»ºè®®
- `[PRAISE]`: å¥½çš„å®è·µï¼Œæ­£é¢åé¦ˆ

**ğŸ’¬ æ²Ÿé€šåŸåˆ™**:
- **å»ºè®¾æ€§**: æä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®ï¼Œè€Œéå•çº¯æ‰¹è¯„
- **æ•™è‚²æ€§**: è§£é‡Šä¸ºä»€ä¹ˆéœ€è¦ä¿®æ”¹ï¼Œå¸®åŠ©å›¢é˜Ÿæˆé•¿
- **åŠæ—¶æ€§**: 24å°æ—¶å†…å®Œæˆreviewï¼Œç´§æ€¥PR 4å°æ—¶å†…
- **å…¨é¢æ€§**: ä¸€æ¬¡æ€§æŒ‡å‡ºæ‰€æœ‰é—®é¢˜ï¼Œé¿å…å¤šè½®åå¤
- **å°Šé‡æ€§**: ä¿æŒä¸“ä¸šå’Œå‹å¥½çš„è¯­è°ƒ

### 1.4 åˆ†æ”¯ç®¡ç†ç­–ç•¥

#### Git Flow å·¥ä½œæµ
```
main (production)     â†â”€ hotfix/xxx
  â†‘                      â†—
develop (integration) â†â”€ release/v1.2.0
  â†‘                      â†—  
feature/new-login â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
feature/api-v2 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### åˆ†æ”¯å‘½åè§„èŒƒ
- `feature/`: æ–°åŠŸèƒ½å¼€å‘ (å¦‚: `feature/user-authentication`)
- `bugfix/`: ç¼ºé™·ä¿®å¤ (å¦‚: `bugfix/login-error`)
- `hotfix/`: ç´§æ€¥ä¿®å¤ (å¦‚: `hotfix/security-patch`)
- `release/`: å‘å¸ƒå‡†å¤‡ (å¦‚: `release/v1.2.0`)
- `chore/`: å·¥ç¨‹ä»»åŠ¡ (å¦‚: `chore/update-dependencies`)

#### Commit Message è§„èŒƒ
```
<type>(<scope>): <subject>

<body>

<footer>
```

**ç±»å‹ (type)**:
- `feat`: æ–°åŠŸèƒ½
- `fix`: ä¿®å¤bug
- `docs`: æ–‡æ¡£æ›´æ–°
- `style`: ä»£ç æ ¼å¼è°ƒæ•´
- `refactor`: é‡æ„ä»£ç 
- `test`: æµ‹è¯•ç›¸å…³
- `chore`: å·¥ç¨‹é…ç½®

**ç¤ºä¾‹**:
```
feat(auth): add multi-factor authentication

- Implement TOTP-based 2FA
- Add backup codes generation
- Update user profile UI

Closes #123
```

---

## 2. è‡ªåŠ¨åŒ–æµ‹è¯•è¦†ç›–ç­–ç•¥ (Automated Test Coverage)

### 2.1 æµ‹è¯•ç­–ç•¥é‡‘å­—å¡”

```
    ğŸ”º E2E Tests (10%)
       UI workflow testing
   
  ğŸ”¶ Integration Tests (20%)
     API integration, service layer
     
ğŸ”» Unit Tests (70%)
   Pure functions, business logic
```

#### æµ‹è¯•åˆ†å±‚ç­–ç•¥

**ğŸ§ª å•å…ƒæµ‹è¯• (Unit Tests) - 70%**
- **ç›®æ ‡**: æµ‹è¯•ç‹¬ç«‹çš„å‡½æ•°ã€æ–¹æ³•ã€ç»„ä»¶
- **å·¥å…·**: Jest (å‰ç«¯), pytest (åç«¯)
- **è¦†ç›–èŒƒå›´**: ä¸šåŠ¡é€»è¾‘ã€å·¥å…·å‡½æ•°ã€Reactç»„ä»¶
- **æ‰§è¡Œé¢‘ç‡**: æ¯æ¬¡ä»£ç æäº¤

**ğŸ”— é›†æˆæµ‹è¯• (Integration Tests) - 20%**
- **ç›®æ ‡**: æµ‹è¯•æœåŠ¡é—´äº¤äº’ã€æ•°æ®åº“æ“ä½œ
- **å·¥å…·**: Jest + MSW (å‰ç«¯), pytest + TestClient (åç«¯)
- **è¦†ç›–èŒƒå›´**: APIç«¯ç‚¹ã€æ•°æ®åº“æ“ä½œã€ç¬¬ä¸‰æ–¹æœåŠ¡é›†æˆ
- **æ‰§è¡Œé¢‘ç‡**: æ¯æ¬¡PRæäº¤

**ğŸ­ ç«¯åˆ°ç«¯æµ‹è¯• (E2E Tests) - 10%**
- **ç›®æ ‡**: æµ‹è¯•å®Œæ•´ç”¨æˆ·æµç¨‹
- **å·¥å…·**: Playwright
- **è¦†ç›–èŒƒå›´**: å…³é”®ä¸šåŠ¡æµç¨‹ã€è·¨ç³»ç»Ÿäº¤äº’
- **æ‰§è¡Œé¢‘ç‡**: å‘å¸ƒå‰ã€å¤œé—´æ„å»º

### 2.2 å‰ç«¯æµ‹è¯•ç­–ç•¥ (Next.js)

#### æ¨èæµ‹è¯•æ¡†æ¶
```json
{
  "devDependencies": {
    "@testing-library/react": "^14.1.2",
    "@testing-library/jest-dom": "^6.1.4",
    "@testing-library/user-event": "^14.5.1",
    "jest": "^29.7.0",
    "jest-environment-jsdom": "^29.7.0"
  }
}
```

#### Jest é…ç½®æ–‡ä»¶ (`jest.config.js`)
```javascript
const nextJest = require('next/jest');

const createJestConfig = nextJest({
  // Provide the path to your Next.js app to load next.config.js and .env files
  dir: './',
});

// Add any custom config to be passed to Jest
const customJestConfig = {
  setupFilesAfterEnv: ['<rootDir>/jest.setup.js'],
  testEnvironment: 'jest-environment-jsdom',
  collectCoverageFrom: [
    'components/**/*.{js,jsx,ts,tsx}',
    'pages/**/*.{js,jsx,ts,tsx}',
    'lib/**/*.{js,jsx,ts,tsx}',
    '!**/*.d.ts',
    '!**/node_modules/**',
    '!**/.next/**',
  ],
  coverageThreshold: {
    global: {
      branches: 80,
      functions: 80,
      lines: 80,
      statements: 80,
    },
  },
  testMatch: [
    '<rootDir>/**/__tests__/**/*.{js,jsx,ts,tsx}',
    '<rootDir>/**/*.{test,spec}.{js,jsx,ts,tsx}',
  ],
  moduleNameMapping: {
    '^@/(.*)$': '<rootDir>/$1',
  },
};

// createJestConfig is exported this way to ensure that next/jest can load config
module.exports = createJestConfig(customJestConfig);
```

#### å•å…ƒæµ‹è¯•ç¤ºä¾‹
```typescript
// components/ui/__tests__/Button.test.tsx
import { render, screen, fireEvent } from '@testing-library/react';
import { Button } from '../Button';

describe('Button Component', () => {
  it('renders button with text', () => {
    render(<Button>Click me</Button>);
    expect(screen.getByRole('button', { name: 'Click me' })).toBeInTheDocument();
  });

  it('applies variant styles correctly', () => {
    render(<Button variant="primary">Primary Button</Button>);
    const button = screen.getByRole('button');
    expect(button).toHaveClass('bg-blue-600');
  });

  it('handles click events', () => {
    const handleClick = jest.fn();
    render(<Button onClick={handleClick}>Click me</Button>);
    
    fireEvent.click(screen.getByRole('button'));
    expect(handleClick).toHaveBeenCalledTimes(1);
  });

  it('shows loading state correctly', () => {
    render(<Button loading>Loading Button</Button>);
    expect(screen.getByRole('button')).toBeDisabled();
    expect(screen.getByTestId('loading-spinner')).toBeInTheDocument();
  });

  it('renders with different sizes', () => {
    const { rerender } = render(<Button size="sm">Small</Button>);
    expect(screen.getByRole('button')).toHaveClass('px-3 py-1.5');
    
    rerender(<Button size="lg">Large</Button>);
    expect(screen.getByRole('button')).toHaveClass('px-6 py-3');
  });
});
```

#### é›†æˆæµ‹è¯•ç¤ºä¾‹
```typescript
// __tests__/api/auth.test.ts
import { createMocks } from 'node-mocks-http';
import handler from '@/pages/api/auth/login';

describe('/api/auth/login', () => {
  it('returns JWT token for valid credentials', async () => {
    const { req, res } = createMocks({
      method: 'POST',
      body: {
        email: 'test@example.com',
        password: 'validpassword',
      },
    });

    await handler(req, res);

    expect(res._getStatusCode()).toBe(200);
    const data = JSON.parse(res._getData());
    expect(data.token).toBeDefined();
    expect(data.user.email).toBe('test@example.com');
  });

  it('returns 401 for invalid credentials', async () => {
    const { req, res } = createMocks({
      method: 'POST',
      body: {
        email: 'test@example.com',
        password: 'wrongpassword',
      },
    });

    await handler(req, res);

    expect(res._getStatusCode()).toBe(401);
    const data = JSON.parse(res._getData());
    expect(data.error).toBe('Invalid credentials');
  });
});
```

### 2.3 åç«¯æµ‹è¯•ç­–ç•¥ (FastAPI)

#### æ¨èæµ‹è¯•æ¡†æ¶
```python
# requirements-dev.txt
pytest==7.4.3
pytest-asyncio==0.21.1
pytest-cov==4.1.0
httpx==0.25.2
factories-boy==3.3.0
```

#### pytest é…ç½®æ–‡ä»¶ (`pytest.ini`)
```ini
[tool:pytest]
minversion = 6.0
addopts = 
    -ra
    --strict-markers
    --strict-config
    --cov=app
    --cov-report=term-missing:skip-covered
    --cov-report=html:htmlcov
    --cov-report=xml
    --cov-fail-under=80
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
asyncio_mode = auto
```

#### æµ‹è¯•å›ºä»¶ (`tests/conftest.py`)
```python
import pytest
from fastapi.testclient import TestClient
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from app.main import app
from app.core.database import get_db
from app.models.base import Base

# Test database
SQLALCHEMY_DATABASE_URL = "sqlite:///./test.db"
engine = create_engine(SQLALCHEMY_DATABASE_URL, connect_args={"check_same_thread": False})
TestingSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

@pytest.fixture(scope="session")
def db():
    Base.metadata.create_all(bind=engine)
    yield
    Base.metadata.drop_all(bind=engine)

@pytest.fixture(scope="function")
def db_session(db):
    connection = engine.connect()
    transaction = connection.begin()
    session = TestingSessionLocal(bind=connection)
    yield session
    session.close()
    transaction.rollback()
    connection.close()

@pytest.fixture(scope="function")
def client(db_session):
    def get_test_db():
        try:
            yield db_session
        finally:
            pass
    
    app.dependency_overrides[get_db] = get_test_db
    with TestClient(app) as test_client:
        yield test_client
    app.dependency_overrides.clear()

@pytest.fixture
def authenticated_client(client, db_session):
    # Create test user and get token
    user_data = {
        "email": "test@example.com",
        "password": "testpassword123"
    }
    
    # Register user
    client.post("/auth/register", json=user_data)
    
    # Login and get token
    response = client.post("/auth/login", json=user_data)
    token = response.json()["access_token"]
    
    # Set authorization header
    client.headers.update({"Authorization": f"Bearer {token}"})
    return client
```

#### å•å…ƒæµ‹è¯•ç¤ºä¾‹
```python
# tests/test_auth.py
import pytest
from app.services.auth import AuthService
from app.models.user import User

class TestAuthService:
    def test_hash_password(self):
        """Test password hashing"""
        password = "testpassword123"
        hashed = AuthService.hash_password(password)
        
        assert hashed != password
        assert AuthService.verify_password(password, hashed)
        assert not AuthService.verify_password("wrongpassword", hashed)
    
    def test_create_access_token(self):
        """Test JWT token creation"""
        user_id = 123
        token = AuthService.create_access_token(user_id)
        
        assert isinstance(token, str)
        assert len(token) > 0
        
        # Verify token payload
        payload = AuthService.decode_token(token)
        assert payload["user_id"] == user_id
        assert "exp" in payload
    
    def test_decode_invalid_token(self):
        """Test decoding invalid token"""
        with pytest.raises(ValueError):
            AuthService.decode_token("invalid.token.here")
```

#### é›†æˆæµ‹è¯•ç¤ºä¾‹
```python
# tests/test_api/test_users.py
import pytest
from fastapi import status

class TestUserAPI:
    def test_create_user_success(self, client):
        """Test successful user creation"""
        user_data = {
            "email": "newuser@example.com",
            "password": "securepassword123",
            "full_name": "New User"
        }
        
        response = client.post("/users", json=user_data)
        
        assert response.status_code == status.HTTP_201_CREATED
        data = response.json()
        assert data["email"] == user_data["email"]
        assert data["full_name"] == user_data["full_name"]
        assert "password" not in data  # Password should not be returned
    
    def test_create_user_duplicate_email(self, client, db_session):
        """Test user creation with duplicate email"""
        user_data = {
            "email": "existing@example.com",
            "password": "password123",
            "full_name": "Existing User"
        }
        
        # Create first user
        client.post("/users", json=user_data)
        
        # Try to create second user with same email
        response = client.post("/users", json=user_data)
        
        assert response.status_code == status.HTTP_400_BAD_REQUEST
        assert "email already exists" in response.json()["detail"].lower()
    
    def test_get_user_profile(self, authenticated_client):
        """Test getting user profile"""
        response = authenticated_client.get("/users/me")
        
        assert response.status_code == status.HTTP_200_OK
        data = response.json()
        assert "email" in data
        assert "full_name" in data
        assert "password" not in data
    
    def test_update_user_profile(self, authenticated_client):
        """Test updating user profile"""
        update_data = {
            "full_name": "Updated Name",
            "bio": "Updated bio"
        }
        
        response = authenticated_client.put("/users/me", json=update_data)
        
        assert response.status_code == status.HTTP_200_OK
        data = response.json()
        assert data["full_name"] == update_data["full_name"]
        assert data["bio"] == update_data["bio"]
```

### 2.4 å®Œæ•´çš„ CI/CD é…ç½®

åˆ›å»º `.github/workflows/ci.yml` æ–‡ä»¶ï¼š

```yaml
name: Continuous Integration

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

env:
  NODE_VERSION: '18'
  PYTHON_VERSION: '3.11'

jobs:
  # ============================================
  # Frontend Testing (Next.js)
  # ============================================
  frontend-test:
    runs-on: ubuntu-latest
    name: Frontend Tests & Build
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Run ESLint
        run: npm run lint
        
      - name: Run TypeScript check
        run: npm run type-check
        
      - name: Run unit tests
        run: npm run test -- --coverage --watchAll=false
        
      - name: Upload frontend coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage/lcov.info
          flags: frontend
          name: frontend-coverage
          fail_ci_if_error: true
          
      - name: Build Next.js application
        run: npm run build
        env:
          NODE_ENV: production
          
      - name: Check bundle size
        run: npm run analyze:size
        
      # Store build artifacts for deployment
      - name: Upload build artifacts
        uses: actions/upload-artifact@v3
        with:
          name: frontend-build
          path: .next
          retention-days: 1

  # ============================================
  # Backend Testing (FastAPI)
  # ============================================
  backend-test:
    runs-on: ubuntu-latest
    name: Backend Tests & Build
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: test_db
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_pass
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
          
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-dev.txt
          
      - name: Run code formatting check (Black)
        run: black --check .
        
      - name: Run import sorting check (isort)
        run: isort --check-only .
        
      - name: Run static type checking (mypy)
        run: mypy app/
        
      - name: Run security checks (bandit)
        run: bandit -r app/ -ll
        
      - name: Run unit and integration tests
        run: pytest --cov=app --cov-report=xml --cov-report=term-missing
        env:
          DATABASE_URL: postgresql://test_user:test_pass@localhost:5432/test_db
          REDIS_URL: redis://localhost:6379/0
          ENVIRONMENT: testing
          
      - name: Upload backend coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage.xml
          flags: backend
          name: backend-coverage
          fail_ci_if_error: true
          
      - name: Build Docker image
        run: |
          docker build -t greenlink-api:${{ github.sha }} -f backend/Dockerfile .
          
      - name: Test Docker image
        run: |
          docker run --rm -d --name test-api -p 8000:8000 \
            -e DATABASE_URL=sqlite:///./test.db \
            greenlink-api:${{ github.sha }}
          sleep 10
          curl -f http://localhost:8000/health || exit 1
          docker stop test-api

  # ============================================
  # End-to-End Testing (Playwright)
  # ============================================
  e2e-test:
    runs-on: ubuntu-latest
    name: End-to-End Tests
    needs: [frontend-test, backend-test]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Install Playwright browsers
        run: npx playwright install --with-deps
        
      - name: Download frontend build
        uses: actions/download-artifact@v3
        with:
          name: frontend-build
          path: .next
          
      - name: Start services for E2E testing
        run: |
          # Start backend in background
          docker-compose -f docker-compose.test.yml up -d
          
          # Start frontend in background
          npm run start &
          
          # Wait for services to be ready
          ./scripts/wait-for-services.sh
          
      - name: Run E2E tests
        run: npx playwright test
        env:
          BASE_URL: http://localhost:3000
          API_URL: http://localhost:8000
          
      - name: Upload E2E test results
        uses: actions/upload-artifact@v3
        if: failure()
        with:
          name: e2e-test-results
          path: test-results/
          
      - name: Upload E2E test report
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: e2e-html-report
          path: playwright-report/

  # ============================================
  # Code Coverage Consolidation
  # ============================================
  coverage-check:
    runs-on: ubuntu-latest
    name: Coverage Validation
    needs: [frontend-test, backend-test]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Download coverage reports
        uses: actions/download-artifact@v3
        
      - name: Validate coverage thresholds
        run: |
          echo "Validating code coverage meets minimum requirements..."
          
          # Check if coverage meets 80% threshold
          frontend_coverage=$(grep -oP 'Lines\s+:\s+\K[\d.]+' frontend-coverage/coverage-summary.txt)
          backend_coverage=$(grep -oP 'TOTAL.*\s+\K\d+' backend-coverage/coverage.txt | tail -1)
          
          if (( $(echo "$frontend_coverage < 80" | bc -l) )); then
            echo "âŒ Frontend coverage ($frontend_coverage%) is below 80% threshold"
            exit 1
          fi
          
          if (( backend_coverage < 80 )); then
            echo "âŒ Backend coverage ($backend_coverage%) is below 80% threshold"
            exit 1  
          fi
          
          echo "âœ… Coverage validation passed"
          echo "ğŸ“Š Frontend: $frontend_coverage%"  
          echo "ğŸ“Š Backend: $backend_coverage%"

  # ============================================
  # Build Status Summary
  # ============================================
  build-summary:
    runs-on: ubuntu-latest
    name: Build Summary
    needs: [frontend-test, backend-test, e2e-test, coverage-check]
    if: always()
    
    steps:
      - name: Generate build summary
        run: |
          echo "## ğŸš€ Build Summary" >> $GITHUB_STEP_SUMMARY
          echo "| Component | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Frontend Tests | ${{ needs.frontend-test.result == 'success' && 'âœ… Passed' || 'âŒ Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Backend Tests | ${{ needs.backend-test.result == 'success' && 'âœ… Passed' || 'âŒ Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| E2E Tests | ${{ needs.e2e-test.result == 'success' && 'âœ… Passed' || 'âŒ Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Coverage Check | ${{ needs.coverage-check.result == 'success' && 'âœ… Passed' || 'âŒ Failed' }} |" >> $GITHUB_STEP_SUMMARY
          
      - name: Determine overall status
        run: |
          if [[ "${{ needs.frontend-test.result }}" == "success" && 
                "${{ needs.backend-test.result }}" == "success" && 
                "${{ needs.e2e-test.result }}" == "success" && 
                "${{ needs.coverage-check.result }}" == "success" ]]; then
            echo "ğŸ‰ All checks passed! Ready for deployment."
            exit 0
          else
            echo "âŒ Some checks failed. Please review and fix issues before merging."
            exit 1
          fi
```

### 2.5 æµ‹è¯•è¦†ç›–ç‡é…ç½®

#### Codecov é…ç½® (`codecov.yml`)
```yaml
coverage:
  status:
    project:
      default:
        target: 80%
        threshold: 2%
        if_no_uploads: error
    patch:
      default:
        target: 80%
        threshold: 2%
        if_no_uploads: error

flag_management:
  default_rules:
    carryforward: true
    statuses:
      - name: frontend-coverage
        type: project
        target: 80%
      - name: backend-coverage  
        type: project
        target: 80%

flags:
  frontend:
    paths:
      - components/
      - pages/
      - lib/
    carryforward: true
  backend:
    paths:
      - app/
    carryforward: true

comment:
  layout: "header, diff, flags, components"
  behavior: default
  require_changes: false
```

---

## 3. æ€§èƒ½åŸºå‡†ç›‘æ§ (Performance Baseline Monitoring)

### 3.1 æ€§èƒ½åŸºå‡†å®šä¹‰

#### Core Web Vitals åŸºå‡†
```yaml
performance_budgets:
  # Core Web Vitals
  core_web_vitals:
    LCP: # Largest Contentful Paint
      good: 2500      # â‰¤ 2.5s
      poor: 4000      # > 4.0s
      
    INP: # Interaction to Next Paint
      good: 200       # â‰¤ 200ms
      poor: 500       # > 500ms
      
    CLS: # Cumulative Layout Shift
      good: 0.1       # â‰¤ 0.1
      poor: 0.25      # > 0.25

  # Resource Budgets
  resource_budgets:
    javascript:
      total: 500000   # 500KB total JS
      main: 200000    # 200KB main bundle
      
    css:
      total: 100000   # 100KB total CSS
      
    images:
      total: 2000000  # 2MB total images
      
    fonts:
      total: 150000   # 150KB fonts

  # Network Budgets
  network_budgets:
    requests: 50      # Max 50 requests
    domains: 5        # Max 5 domains
    
  # Runtime Budgets
  runtime_budgets:
    main_thread:
      total: 4000     # 4s max main thread blocking
      long_tasks: 50  # 50ms max individual task
```

#### API æ€§èƒ½åŸºå‡†
```yaml
api_performance_budgets:
  # Response Time Budgets (95th percentile)
  response_times:
    authentication: 200   # 200ms
    user_profile: 150     # 150ms
    asset_listing: 300    # 300ms
    trading_orders: 500   # 500ms
    reporting: 1000       # 1s

  # Throughput Budgets
  throughput:
    peak_rps: 1000        # 1000 requests/second
    concurrent_users: 500  # 500 concurrent users
    
  # Error Rate Budgets
  error_rates:
    4xx_errors: 5         # 5% max client errors
    5xx_errors: 1         # 1% max server errors
    timeout_errors: 0.5   # 0.5% max timeout errors
```

### 3.2 Lighthouse CI é›†æˆ

#### Lighthouse CI é…ç½® (`lighthouserc.js`)
```javascript
module.exports = {
  ci: {
    collect: {
      url: [
        'http://localhost:3000',
        'http://localhost:3000/login',
        'http://localhost:3000/dashboard',
        'http://localhost:3000/assets',
        'http://localhost:3000/trading',
      ],
      startServerCommand: 'npm run start',
      startServerReadyPattern: 'ready on',
      startServerReadyTimeout: 30000,
      numberOfRuns: 3,
      settings: {
        chromeFlags: '--no-sandbox --disable-dev-shm-usage',
        preset: 'desktop',
        throttling: {
          rttMs: 40,
          throughputKbps: 10240,
          cpuSlowdownMultiplier: 1,
          requestLatencyMs: 0,
          downloadThroughputKbps: 0,
          uploadThroughputKbps: 0,
        },
        auditMode: false,
        gatherMode: false,
        disableStorageReset: false,
        emulatedFormFactor: 'desktop',
        internalDisableDeviceScreenEmulation: true,
      },
    },
    assert: {
      assertions: {
        'categories:performance': ['error', { minScore: 0.8 }],
        'categories:accessibility': ['error', { minScore: 0.9 }],
        'categories:best-practices': ['error', { minScore: 0.9 }],
        'categories:seo': ['error', { minScore: 0.8 }],
        
        // Core Web Vitals
        'largest-contentful-paint': ['error', { maxNumericValue: 2500 }],
        'cumulative-layout-shift': ['error', { maxNumericValue: 0.1 }],
        'total-blocking-time': ['error', { maxNumericValue: 200 }],
        
        // Resource budgets
        'total-byte-weight': ['error', { maxNumericValue: 1500000 }], // 1.5MB
        'unused-javascript': ['warn', { maxNumericValue: 50000 }],    // 50KB
        'unused-css-rules': ['warn', { maxNumericValue: 20000 }],     // 20KB
        
        // Network efficiency
        'uses-optimized-images': 'error',
        'uses-webp-images': 'warn',
        'uses-text-compression': 'error',
        'uses-responsive-images': 'error',
        
        // JavaScript performance
        'unminified-javascript': 'error',
        'unused-javascript': 'warn',
        'legacy-javascript': 'warn',
        
        // Rendering performance
        'dom-size': ['warn', { maxNumericValue: 1500 }],
        'no-document-write': 'error',
        'uses-passive-event-listeners': 'warn',
      },
    },
    upload: {
      target: 'temporary-public-storage',
      reportFilenamePattern: '%%PATHNAME%%-%%DATETIME%%-report.%%EXTENSION%%',
    },
    server: {
      port: 9001,
      storage: './lighthouse-reports',
    },
  },
};
```

#### Performance ç›‘æ§ GitHub Action
```yaml
# .github/workflows/performance.yml
name: Performance Testing

on:
  pull_request:
    branches: [ main, develop ]
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM

jobs:
  lighthouse-ci:
    runs-on: ubuntu-latest
    name: Lighthouse Performance Audit
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Build application
        run: npm run build
        env:
          NODE_ENV: production
          
      - name: Run Lighthouse CI
        run: |
          npm install -g @lhci/cli@0.12.x
          lhci autorun
        env:
          LHCI_GITHUB_APP_TOKEN: ${{ secrets.LHCI_GITHUB_APP_TOKEN }}
          
      - name: Upload Lighthouse reports
        uses: actions/upload-artifact@v3
        if: failure()
        with:
          name: lighthouse-reports
          path: lighthouse-reports/
          
      - name: Performance regression check
        run: |
          # Compare with baseline metrics
          node scripts/performance-comparison.js
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  # API Performance Testing
  api-performance:
    runs-on: ubuntu-latest
    name: API Performance Testing
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: test_db
          POSTGRES_USER: test_user  
          POSTGRES_PASSWORD: test_pass
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install locust pytest-benchmark
          
      - name: Start API server
        run: |
          uvicorn app.main:app --host 0.0.0.0 --port 8000 &
          sleep 10
        env:
          DATABASE_URL: postgresql://test_user:test_pass@localhost:5432/test_db
          
      - name: Run API load tests
        run: |
          locust -f tests/performance/locustfile.py \
                 --host=http://localhost:8000 \
                 --users=100 \
                 --spawn-rate=10 \
                 --run-time=60s \
                 --headless \
                 --html=performance-report.html
                 
      - name: Run benchmark tests
        run: pytest tests/performance/benchmarks/ -v --benchmark-json=benchmark.json
        
      - name: Analyze performance results
        run: |
          python scripts/analyze-performance.py \
            --locust-report=performance-report.html \
            --benchmark-results=benchmark.json \
            --baseline=performance-baseline.json
            
      - name: Upload performance reports
        uses: actions/upload-artifact@v3
        with:
          name: performance-reports
          path: |
            performance-report.html
            benchmark.json
```

### 3.3 æ€§èƒ½ç›‘æ§è„šæœ¬

#### æ€§èƒ½å¯¹æ¯”è„šæœ¬ (`scripts/performance-comparison.js`)
```javascript
const fs = require('fs');
const path = require('path');

class PerformanceComparator {
  constructor() {
    this.thresholds = {
      performance: 0.8,
      accessibility: 0.9,
      'best-practices': 0.9,
      seo: 0.8,
      lcp: 2500,
      cls: 0.1,
      tbt: 200,
    };
  }

  async compareResults() {
    try {
      const currentResults = await this.loadLighthouseResults();
      const baselineResults = await this.loadBaselineResults();
      
      const comparison = this.performComparison(currentResults, baselineResults);
      
      await this.generateReport(comparison);
      await this.checkThresholds(comparison);
      
    } catch (error) {
      console.error('Performance comparison failed:', error);
      process.exit(1);
    }
  }

  async loadLighthouseResults() {
    const resultsDir = './lighthouse-reports';
    const files = fs.readdirSync(resultsDir)
      .filter(file => file.endsWith('.json'))
      .sort()
      .slice(-1); // Get latest result
      
    if (files.length === 0) {
      throw new Error('No Lighthouse results found');
    }
    
    const latestResult = JSON.parse(
      fs.readFileSync(path.join(resultsDir, files[0]), 'utf8')
    );
    
    return this.extractMetrics(latestResult);
  }

  async loadBaselineResults() {
    const baselinePath = './performance-baseline.json';
    
    if (!fs.existsSync(baselinePath)) {
      console.warn('No baseline found, creating new baseline');
      return null;
    }
    
    return JSON.parse(fs.readFileSync(baselinePath, 'utf8'));
  }

  extractMetrics(lighthouseResult) {
    const { categories, audits } = lighthouseResult;
    
    return {
      scores: {
        performance: categories.performance.score,
        accessibility: categories.accessibility.score,
        'best-practices': categories['best-practices'].score,
        seo: categories.seo.score,
      },
      metrics: {
        lcp: audits['largest-contentful-paint'].numericValue,
        cls: audits['cumulative-layout-shift'].numericValue,
        tbt: audits['total-blocking-time'].numericValue,
        fcp: audits['first-contentful-paint'].numericValue,
        si: audits['speed-index'].numericValue,
      },
      resourceSizes: {
        totalBytes: audits['total-byte-weight'].numericValue,
        jsBytes: audits['total-byte-weight'].details.items
          .filter(item => item.resourceType === 'script')
          .reduce((sum, item) => sum + item.transferSize, 0),
        cssBytes: audits['total-byte-weight'].details.items
          .filter(item => item.resourceType === 'stylesheet')
          .reduce((sum, item) => sum + item.transferSize, 0),
      },
      timestamp: Date.now(),
      url: lighthouseResult.finalUrl,
    };
  }

  performComparison(current, baseline) {
    if (!baseline) {
      return {
        current,
        baseline: null,
        changes: {},
        regressions: [],
        improvements: [],
      };
    }

    const changes = {};
    const regressions = [];
    const improvements = [];

    // Compare scores
    Object.keys(current.scores).forEach(key => {
      const currentValue = current.scores[key];
      const baselineValue = baseline.scores[key];
      const change = currentValue - baselineValue;
      
      changes[key] = {
        current: currentValue,
        baseline: baselineValue,
        change: change,
        changePercent: (change / baselineValue) * 100,
      };
      
      if (change < -0.05) { // 5% regression threshold
        regressions.push({
          metric: key,
          type: 'score',
          ...changes[key],
        });
      } else if (change > 0.05) {
        improvements.push({
          metric: key,
          type: 'score',
          ...changes[key],
        });
      }
    });

    // Compare metrics (lower is better)
    Object.keys(current.metrics).forEach(key => {
      const currentValue = current.metrics[key];
      const baselineValue = baseline.metrics[key];
      const change = currentValue - baselineValue;
      
      changes[key] = {
        current: currentValue,
        baseline: baselineValue,
        change: change,
        changePercent: (change / baselineValue) * 100,
      };
      
      if (change > baselineValue * 0.1) { // 10% regression threshold
        regressions.push({
          metric: key,
          type: 'metric',
          ...changes[key],
        });
      } else if (change < -baselineValue * 0.1) {
        improvements.push({
          metric: key,
          type: 'metric',
          ...changes[key],
        });
      }
    });

    return {
      current,
      baseline,
      changes,
      regressions,
      improvements,
    };
  }

  async generateReport(comparison) {
    const { current, baseline, changes, regressions, improvements } = comparison;
    
    let report = '# ğŸš€ Performance Report\n\n';
    
    // Current metrics
    report += '## ğŸ“Š Current Metrics\n\n';
    report += '| Metric | Score/Value | Status |\n';
    report += '|--------|-------------|--------|\n';
    
    Object.entries(current.scores).forEach(([key, value]) => {
      const threshold = this.thresholds[key];
      const status = value >= threshold ? 'âœ… Pass' : 'âŒ Fail';
      report += `| ${key} | ${(value * 100).toFixed(1)}% | ${status} |\n`;
    });
    
    Object.entries(current.metrics).forEach(([key, value]) => {
      const threshold = this.thresholds[key];
      const status = value <= threshold ? 'âœ… Pass' : 'âŒ Fail';
      const unit = ['lcp', 'fcp', 'tbt', 'si'].includes(key) ? 'ms' : '';
      report += `| ${key.toUpperCase()} | ${value.toFixed(1)}${unit} | ${status} |\n`;
    });

    // Comparison with baseline
    if (baseline) {
      report += '\n## ğŸ“ˆ Comparison with Baseline\n\n';
      
      if (regressions.length > 0) {
        report += '### âš ï¸ Performance Regressions\n\n';
        regressions.forEach(reg => {
          const unit = reg.type === 'metric' ? 'ms' : '%';
          report += `- **${reg.metric}**: ${reg.baseline.toFixed(1)}${unit} â†’ ${reg.current.toFixed(1)}${unit} (${reg.changePercent > 0 ? '+' : ''}${reg.changePercent.toFixed(1)}%)\n`;
        });
        report += '\n';
      }
      
      if (improvements.length > 0) {
        report += '### ğŸ‰ Performance Improvements\n\n';
        improvements.forEach(imp => {
          const unit = imp.type === 'metric' ? 'ms' : '%';
          report += `- **${imp.metric}**: ${imp.baseline.toFixed(1)}${unit} â†’ ${imp.current.toFixed(1)}${unit} (${imp.changePercent > 0 ? '+' : ''}${imp.changePercent.toFixed(1)}%)\n`;
        });
        report += '\n';
      }
    }

    // Resource sizes
    report += '## ğŸ’¾ Resource Sizes\n\n';
    report += `- **Total**: ${(current.resourceSizes.totalBytes / 1024).toFixed(1)} KB\n`;
    report += `- **JavaScript**: ${(current.resourceSizes.jsBytes / 1024).toFixed(1)} KB\n`;
    report += `- **CSS**: ${(current.resourceSizes.cssBytes / 1024).toFixed(1)} KB\n\n`;

    // Save report
    fs.writeFileSync('./performance-report.md', report);
    console.log('Performance report generated: ./performance-report.md');
    
    // Output to GitHub Actions summary
    if (process.env.GITHUB_STEP_SUMMARY) {
      fs.appendFileSync(process.env.GITHUB_STEP_SUMMARY, report);
    }
  }

  async checkThresholds(comparison) {
    const { current, regressions } = comparison;
    let hasFailures = false;

    // Check score thresholds
    Object.entries(current.scores).forEach(([key, value]) => {
      const threshold = this.thresholds[key];
      if (value < threshold) {
        console.error(`âŒ ${key} score (${(value * 100).toFixed(1)}%) is below threshold (${(threshold * 100).toFixed(1)}%)`);
        hasFailures = true;
      }
    });

    // Check metric thresholds
    Object.entries(current.metrics).forEach(([key, value]) => {
      const threshold = this.thresholds[key];
      if (threshold && value > threshold) {
        console.error(`âŒ ${key.toUpperCase()} (${value.toFixed(1)}ms) exceeds threshold (${threshold}ms)`);
        hasFailures = true;
      }
    });

    // Check for significant regressions
    if (regressions.length > 0) {
      console.error(`âŒ Found ${regressions.length} performance regressions`);
      hasFailures = true;
    }

    if (hasFailures) {
      console.error('\nğŸ’¥ Performance check failed! Please review and optimize before merging.');
      process.exit(1);
    } else {
      console.log('\nâœ… All performance checks passed!');
    }
  }
}

// Run comparison
const comparator = new PerformanceComparator();
comparator.compareResults().catch(console.error);
```

### 3.4 API æ€§èƒ½æµ‹è¯•

#### Locust è´Ÿè½½æµ‹è¯• (`tests/performance/locustfile.py`)
```python
from locust import HttpUser, TaskSet, task, between
import random
import json

class UserBehavior(TaskSet):
    def on_start(self):
        """Initialize user session"""
        self.login()
    
    def login(self):
        """Authenticate user"""
        login_data = {
            "email": f"user{random.randint(1, 1000)}@example.com",
            "password": "testpassword123"
        }
        
        response = self.client.post("/auth/login", json=login_data)
        if response.status_code == 200:
            token = response.json().get("access_token")
            self.client.headers.update({"Authorization": f"Bearer {token}"})
    
    @task(3)
    def view_dashboard(self):
        """User views dashboard"""
        self.client.get("/users/me/dashboard")
    
    @task(2)
    def list_assets(self):
        """User lists available assets"""
        self.client.get("/assets?limit=20&offset=0")
    
    @task(2)
    def view_asset_details(self):
        """User views specific asset details"""
        asset_id = random.randint(1, 100)
        self.client.get(f"/assets/{asset_id}")
    
    @task(1)
    def create_order(self):
        """User creates trading order"""
        order_data = {
            "asset_id": random.randint(1, 100),
            "order_type": "buy",
            "quantity": random.randint(1, 10),
            "price": round(random.uniform(100, 1000), 2)
        }
        self.client.post("/orders", json=order_data)
    
    @task(1)
    def view_portfolio(self):
        """User views portfolio"""
        self.client.get("/users/me/portfolio")
    
    @task(1)
    def generate_report(self):
        """User generates performance report"""
        report_params = {
            "period": "monthly",
            "format": "json"
        }
        self.client.get("/users/me/reports", params=report_params)

class APIUser(HttpUser):
    tasks = [UserBehavior]
    wait_time = between(1, 3)  # Wait 1-3 seconds between tasks
    
    def on_start(self):
        """Setup before user starts"""
        pass
```

#### API åŸºå‡†æµ‹è¯• (`tests/performance/benchmarks/test_api_benchmarks.py`)
```python
import pytest
import asyncio
from httpx import AsyncClient
from app.main import app

@pytest.mark.asyncio
@pytest.mark.benchmark
class TestAPIBenchmarks:
    
    @pytest.mark.benchmark(group="auth")
    async def test_login_performance(self, benchmark):
        """Benchmark user login endpoint"""
        async def login():
            async with AsyncClient(app=app, base_url="http://test") as ac:
                response = await ac.post("/auth/login", json={
                    "email": "test@example.com",
                    "password": "testpassword123"
                })
                return response
        
        result = await benchmark.pedantic(login, rounds=100)
        assert result.status_code == 200
        assert "access_token" in result.json()
    
    @pytest.mark.benchmark(group="assets")
    async def test_asset_listing_performance(self, benchmark, authenticated_client):
        """Benchmark asset listing endpoint"""
        async def list_assets():
            response = await authenticated_client.get("/assets?limit=20")
            return response
        
        result = await benchmark.pedantic(list_assets, rounds=50)
        assert result.status_code == 200
        assert len(result.json()["items"]) <= 20
    
    @pytest.mark.benchmark(group="orders")
    async def test_order_creation_performance(self, benchmark, authenticated_client):
        """Benchmark order creation endpoint"""
        order_data = {
            "asset_id": 1,
            "order_type": "buy",
            "quantity": 5,
            "price": 150.50
        }
        
        async def create_order():
            response = await authenticated_client.post("/orders", json=order_data)
            return response
        
        result = await benchmark.pedantic(create_order, rounds=30)
        assert result.status_code == 201
    
    @pytest.mark.benchmark(group="reports")
    async def test_report_generation_performance(self, benchmark, authenticated_client):
        """Benchmark report generation endpoint"""
        async def generate_report():
            response = await authenticated_client.get("/users/me/reports?period=monthly")
            return response
        
        result = await benchmark.pedantic(generate_report, rounds=10)
        assert result.status_code == 200
        assert "data" in result.json()

@pytest.fixture
async def authenticated_client():
    """Provide authenticated HTTP client for benchmarks"""
    async with AsyncClient(app=app, base_url="http://test") as ac:
        # Login and get token
        response = await ac.post("/auth/login", json={
            "email": "test@example.com",
            "password": "testpassword123"
        })
        token = response.json()["access_token"]
        
        # Set authorization header
        ac.headers.update({"Authorization": f"Bearer {token}"})
        yield ac
```

---

## 4. è‡ªåŠ¨åŒ–å®‰å…¨æ‰«æ (Automated Security Scanning)

### 4.1 å®‰å…¨æ‰«æå·¥å…·é›†æˆ

#### æ‰«æç±»å‹ä¸å·¥å…·é€‰æ‹©

**ğŸ” é™æ€ä»£ç åˆ†æ (SAST - Static Application Security Testing)**
- **CodeQL**: GitHubåŸç”Ÿé›†æˆï¼Œæ”¯æŒå¤šè¯­è¨€æ¼æ´æ£€æµ‹
- **Semgrep**: å¿«é€Ÿçš„é™æ€åˆ†æå·¥å…·ï¼Œè§„åˆ™ä¸°å¯Œ
- **Bandit**: Pythonä¸“ç”¨å®‰å…¨æ‰«æå·¥å…·

**ğŸ“¦ è½¯ä»¶æˆåˆ†åˆ†æ (SCA - Software Composition Analysis)**
- **Snyk**: ä¾èµ–é¡¹æ¼æ´æ£€æµ‹å’Œä¿®å¤å»ºè®®
- **Dependabot**: GitHubåŸç”Ÿä¾èµ–æ›´æ–°å’Œå®‰å…¨å‘Šè­¦
- **OWASP Dependency Check**: å¼€æºä¾èµ–æ¼æ´æ‰«æ

**ğŸ³ å®¹å™¨é•œåƒæ‰«æ (Container Security)**
- **Trivy**: å®¹å™¨é•œåƒå’Œæ–‡ä»¶ç³»ç»Ÿæ¼æ´æ‰«æ
- **Docker Scout**: Dockerå®˜æ–¹å®‰å…¨æ‰«æ
- **Anchore**: ä¼ä¸šçº§å®¹å™¨å®‰å…¨åˆ†æ

### 4.2 å®Œæ•´çš„å®‰å…¨æ‰«æå·¥ä½œæµ

åœ¨ç°æœ‰çš„ CI å·¥ä½œæµä¸­æ·»åŠ å®‰å…¨æ‰«æä»»åŠ¡ï¼š

```yaml
# .github/workflows/security.yml
name: Security Scanning

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    - cron: '0 6 * * 1'  # Weekly on Monday at 6 AM

env:
  NODE_VERSION: '18'
  PYTHON_VERSION: '3.11'

jobs:
  # ============================================
  # Static Application Security Testing (SAST)
  # ============================================
  codeql-analysis:
    name: CodeQL Security Analysis
    runs-on: ubuntu-latest
    permissions:
      actions: read
      contents: read
      security-events: write
    
    strategy:
      fail-fast: false
      matrix:
        language: ['javascript', 'python']
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Initialize CodeQL
        uses: github/codeql-action/init@v2
        with:
          languages: ${{ matrix.language }}
          queries: security-extended,security-and-quality
          
      - name: Setup Node.js (for JavaScript analysis)
        if: matrix.language == 'javascript'
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Install frontend dependencies
        if: matrix.language == 'javascript'
        run: npm ci
        
      - name: Build Next.js application
        if: matrix.language == 'javascript'
        run: npm run build
        
      - name: Setup Python (for Python analysis)
        if: matrix.language == 'python'
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          
      - name: Install backend dependencies
        if: matrix.language == 'python'
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: Perform CodeQL Analysis
        uses: github/codeql-action/analyze@v2
        with:
          category: "/language:${{matrix.language}}"

  # ============================================
  # Semgrep SAST Scanning
  # ============================================
  semgrep-scan:
    name: Semgrep Security Scan
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Run Semgrep
        uses: semgrep/semgrep-action@v1
        with:
          config: >-
            p/security-audit
            p/secrets
            p/owasp-top-ten
            p/react
            p/python
            p/typescript
        env:
          SEMGREP_APP_TOKEN: ${{ secrets.SEMGREP_APP_TOKEN }}

  # ============================================
  # Python Security Scanning (Bandit)
  # ============================================
  bandit-scan:
    name: Bandit Python Security Scan
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          
      - name: Install Bandit
        run: pip install bandit[toml]
        
      - name: Run Bandit security scan
        run: |
          bandit -r app/ -f json -o bandit-report.json || true
          bandit -r app/ -f txt
          
      - name: Upload Bandit results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: bandit-results
          path: bandit-report.json

  # ============================================
  # Software Composition Analysis (SCA)
  # ============================================
  snyk-scan:
    name: Snyk Vulnerability Scan
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Run Snyk to check for vulnerabilities
        uses: snyk/actions/node@master
        continue-on-error: true
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        with:
          args: --severity-threshold=high --json-file-output=snyk-report.json
          
      - name: Upload Snyk results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: snyk-results
          path: snyk-report.json
          
      - name: Run Snyk for Python dependencies
        run: |
          npm install -g snyk
          snyk auth ${{ secrets.SNYK_TOKEN }}
          snyk test --file=requirements.txt --package-manager=pip \
                   --severity-threshold=high \
                   --json > snyk-python-report.json || true
          
      - name: Upload Python Snyk results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: snyk-python-results
          path: snyk-python-report.json

  # ============================================
  # OWASP Dependency Check
  # ============================================
  dependency-check:
    name: OWASP Dependency Check
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Run OWASP Dependency Check
        uses: dependency-check/Dependency-Check_Action@main
        with:
          project: 'GreenLink Capital'
          path: '.'
          format: 'ALL'
          args: >
            --enableRetired
            --enableExperimental
            --failOnCVSS 7
            --exclude "**/node_modules/**"
            --exclude "**/test/**"
            --exclude "**/*test*"
            
      - name: Upload OWASP results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: owasp-dependency-check-results
          path: reports/

  # ============================================
  # Container Security Scanning
  # ============================================
  trivy-scan:
    name: Trivy Container Security Scan
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Build Docker images
        run: |
          # Build frontend image
          docker build -t greenlink-frontend:${{ github.sha }} -f Dockerfile .
          
          # Build backend image  
          docker build -t greenlink-backend:${{ github.sha }} -f backend/Dockerfile ./backend
          
      - name: Run Trivy vulnerability scanner - Frontend
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: 'greenlink-frontend:${{ github.sha }}'
          format: 'sarif'
          output: 'trivy-frontend-results.sarif'
          severity: 'CRITICAL,HIGH,MEDIUM'
          
      - name: Run Trivy vulnerability scanner - Backend
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: 'greenlink-backend:${{ github.sha }}'
          format: 'sarif'
          output: 'trivy-backend-results.sarif'
          severity: 'CRITICAL,HIGH,MEDIUM'
          
      - name: Upload Trivy scan results to GitHub Security tab
        uses: github/codeql-action/upload-sarif@v2
        if: always()
        with:
          sarif_file: '.'
          
      - name: Generate Trivy HTML reports
        run: |
          docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
            -v ${{ github.workspace }}:/workspace -w /workspace \
            aquasec/trivy image --format template --template "@contrib/html.tpl" \
            -o trivy-frontend-report.html greenlink-frontend:${{ github.sha }}
            
          docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
            -v ${{ github.workspace }}:/workspace -w /workspace \
            aquasec/trivy image --format template --template "@contrib/html.tpl" \
            -o trivy-backend-report.html greenlink-backend:${{ github.sha }}
            
      - name: Upload Trivy HTML reports
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: trivy-reports
          path: |
            trivy-frontend-report.html
            trivy-backend-report.html

  # ============================================
  # Secret Scanning
  # ============================================
  secret-scan:
    name: Secret Detection Scan
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Fetch full history for secret scanning
          
      - name: Run TruffleHog
        uses: trufflesecurity/trufflehog@main
        with:
          path: ./
          base: main
          head: HEAD
          extra_args: --debug --only-verified
          
      - name: Run GitLeaks
        uses: gitleaks/gitleaks-action@v2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITLEAKS_LICENSE: ${{ secrets.GITLEAKS_LICENSE }}

  # ============================================
  # Security Consolidation & Reporting
  # ============================================
  security-report:
    name: Security Report Consolidation
    runs-on: ubuntu-latest
    needs: [codeql-analysis, semgrep-scan, bandit-scan, snyk-scan, dependency-check, trivy-scan, secret-scan]
    if: always()
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Download all security artifacts
        uses: actions/download-artifact@v3
        
      - name: Setup Python for report generation
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          
      - name: Install report dependencies
        run: |
          pip install jinja2 requests
          
      - name: Generate consolidated security report
        run: |
          python scripts/generate-security-report.py \
            --bandit-report bandit-results/bandit-report.json \
            --snyk-report snyk-results/snyk-report.json \
            --snyk-python-report snyk-python-results/snyk-python-report.json \
            --owasp-report owasp-dependency-check-results/ \
            --output security-report.html
            
issues: read
      - name: Check security thresholds
        run: |
          python scripts/check-security-thresholds.py \
            --report security-report.html \
            --max-critical 0 \
            --max-high 5 \
            --max-medium 20
            
      - name: Upload consolidated security report
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: security-report
          path: |
            security-report.html
            security-summary.json
            
      - name: Comment PR with security summary
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            try {
              const summary = JSON.parse(fs.readFileSync('security-summary.json', 'utf8'));
              
              const comment = `## ğŸ”’ Security Scan Results
              
              | Scanner | Critical | High | Medium | Low |
              |---------|----------|------|--------|-----|
              | Bandit | ${summary.bandit.critical} | ${summary.bandit.high} | ${summary.bandit.medium} | ${summary.bandit.low} |
              | Snyk (Node) | ${summary.snyk.critical} | ${summary.snyk.high} | ${summary.snyk.medium} | ${summary.snyk.low} |
              | Snyk (Python) | ${summary.snyk_python.critical} | ${summary.snyk_python.high} | ${summary.snyk_python.medium} | ${summary.snyk_python.low} |
              | OWASP | ${summary.owasp.critical} | ${summary.owasp.high} | ${summary.owasp.medium} | ${summary.owasp.low} |
              | Trivy | ${summary.trivy.critical} | ${summary.trivy.high} | ${summary.trivy.medium} | ${summary.trivy.low} |
              
              **Overall Status**: ${summary.overall_status}
              
              ${summary.critical_count > 0 ? 'âš ï¸ **Action Required**: Critical vulnerabilities found!' : 'âœ… No critical vulnerabilities detected'}
              
              [View Detailed Report](${summary.report_url})`;
              
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            } catch (error) {
              console.log('Could not read security summary:', error);
            }
```

### 4.3 å®‰å…¨æ‰«æé…ç½®æ–‡ä»¶

#### Bandit é…ç½® (`.bandit`)
```yaml
# Bandit security scanner configuration
exclude_dirs:
  - "/tests"
  - "/test"
  - "*/test_*"
  - "*/tests/*"
  - "/node_modules"
  
skips:
  - B101  # Skip assert_used test in test files
  - B601  # Skip shell injection for paramiko usage
  
tests:
  - B201  # Flask debug mode
  - B301  # Pickle usage  
  - B302  # Deserialization
  - B303  # MD5 usage
  - B304  # Insecure cipher usage
  - B305  # Cipher modes
  - B306  # mktemp usage
  - B307  # eval usage
  - B308  # mark_safe usage
  - B309  # HTTPSConnection
  - B310  # urllib urlopen
  - B311  # Random generators
  - B312  # Telnet usage
  - B313  # XML vulnerabilities
  - B314  # XML vulnerabilities
  - B315  # XML vulnerabilities
  - B316  # XML vulnerabilities
  - B317  # XML vulnerabilities
  - B318  # XML vulnerabilities
  - B319  # XML vulnerabilities
  - B320  # XML vulnerabilities
  - B321  # FTP usage
  - B322  # Input validation
  - B323  # Unverified context
  - B324  # hashlib usage
  - B325  # tempfile usage
  - B401  # Import usage
  - B402  # Import usage
  - B403  # Import usage
  - B404  # Import usage
  - B405  # Import usage
  - B406  # Import usage
  - B407  # Import usage
  - B408  # Import usage
  - B409  # Import usage
  - B410  # Import usage
  - B411  # Import usage
  - B412  # Import usage
  - B501  # Request usage
  - B502  # SSL usage
  - B503  # SSL usage
  - B504  # SSL usage
  - B505  # Weak crypto
  - B506  # YAML load
  - B507  # SSH usage
  - B601  # Shell injection
  - B602  # Subprocess usage
  - B603  # Subprocess usage
  - B604  # shell usage
  - B605  # shell usage
  - B606  # shell usage
  - B607  # shell usage
  - B608  # SQL injection
  - B609  # Linux commands
  - B610  # Django usage
  - B611  # Django usage
  - B701  # jinja2 usage
  - B702  # Test results
  - B703  # Django usage

severity: "medium"
confidence: "medium"
```

#### Semgrep é…ç½® (`.semgrep.yml`)
```yaml
rules:
  - id: hardcoded-secrets
    patterns:
      - pattern-either:
          - pattern: password = "..."
          - pattern: api_key = "..."
          - pattern: secret = "..."
          - pattern: token = "..."
    message: Hardcoded secret detected
    languages: [python, javascript, typescript]
    severity: ERROR
    
  - id: sql-injection-risk
    patterns:
      - pattern-either:
          - pattern: cursor.execute("... " + $VAR + " ...")
          - pattern: cursor.execute(f"... {$VAR} ...")
          - pattern: query = "... " + $VAR + " ..."
    message: Potential SQL injection vulnerability
    languages: [python]
    severity: ERROR
    
  - id: xss-risk-react
    patterns:
      - pattern-either:
          - pattern: dangerouslySetInnerHTML={{__html: $VAR}}
          - pattern: React.createElement("script", ...)
    message: Potential XSS vulnerability in React
    languages: [javascript, typescript]
    severity: WARNING
    
  - id: weak-crypto
    patterns:
      - pattern-either:
          - pattern: hashlib.md5(...)
          - pattern: hashlib.sha1(...)
          - pattern: crypto.createHash("md5")
          - pattern: crypto.createHash("sha1")
    message: Weak cryptographic algorithm used
    languages: [python, javascript]
    severity: WARNING
```

### 4.4 å®‰å…¨æŠ¥å‘Šç”Ÿæˆè„šæœ¬

#### å®‰å…¨æŠ¥å‘Šæ•´åˆè„šæœ¬ (`scripts/generate-security-report.py`)
```python
#!/usr/bin/env python3
import json
import argparse
import os
from datetime import datetime
from jinja2 import Template

class SecurityReportGenerator:
    def __init__(self):
        self.results = {
            'bandit': {'critical': 0, 'high': 0, 'medium': 0, 'low': 0, 'issues': []},
            'snyk': {'critical': 0, 'high': 0, 'medium': 0, 'low': 0, 'issues': []},
            'snyk_python': {'critical': 0, 'high': 0, 'medium': 0, 'low': 0, 'issues': []},
            'owasp': {'critical': 0, 'high': 0, 'medium': 0, 'low': 0, 'issues': []},
            'trivy': {'critical': 0, 'high': 0, 'medium': 0, 'low': 0, 'issues': []},
        }
        
    def parse_bandit_report(self, file_path):
        """Parse Bandit JSON report"""
        if not os.path.exists(file_path):
            return
            
        with open(file_path, 'r') as f:
            data = json.load(f)
            
        for result in data.get('results', []):
            severity = result.get('issue_severity', '').lower()
            confidence = result.get('issue_confidence', '').lower()
            
            # Map Bandit severity to standard levels
            if severity == 'high' and confidence == 'high':
                level = 'critical'
            elif severity == 'high':
                level = 'high'
            elif severity == 'medium':
                level = 'medium'
            else:
                level = 'low'
                
            self.results['bandit'][level] += 1
            self.results['bandit']['issues'].append({
                'severity': level,
                'title': result.get('test_name', 'Unknown'),
                'description': result.get('issue_text', ''),
                'file': result.get('filename', ''),
                'line': result.get('line_number', 0),
                'confidence': confidence
            })
    
    def parse_snyk_report(self, file_path, result_key='snyk'):
        """Parse Snyk JSON report"""
        if not os.path.exists(file_path):
            return
            
        with open(file_path, 'r') as f:
            data = json.load(f)
            
        vulnerabilities = data.get('vulnerabilities', [])
        for vuln in vulnerabilities:
            severity = vuln.get('severity', '').lower()
            
            if severity == 'critical':
                level = 'critical'
            elif severity == 'high':
                level = 'high'
            elif severity == 'medium':
                level = 'medium'
            else:
                level = 'low'
                
            self.results[result_key][level] += 1
            self.results[result_key]['issues'].append({
                'severity': level,
                'title': vuln.get('title', 'Unknown vulnerability'),
                'description': vuln.get('description', ''),
                'package': vuln.get('packageName', ''),
                'version': vuln.get('version', ''),
                'cve': vuln.get('identifiers', {}).get('CVE', []),
                'cwe': vuln.get('identifiers', {}).get('CWE', [])
            })
    
    def parse_owasp_report(self, directory_path):
        """Parse OWASP Dependency Check JSON report"""
        json_file = os.path.join(directory_path, 'dependency-check-report.json')
        if not os.path.exists(json_file):
            return
            
        with open(json_file, 'r') as f:
            data = json.load(f)
            
        dependencies = data.get('dependencies', [])
        for dep in dependencies:
            vulnerabilities = dep.get('vulnerabilities', [])
            for vuln in vulnerabilities:
                severity = vuln.get('severity', '').lower()
                
                # Map CVSS score to severity if needed
                cvss_score = vuln.get('cvssv3', {}).get('baseScore', 0)
                if cvss_score >= 9.0:
                    level = 'critical'
                elif cvss_score >= 7.0:
                    level = 'high'
                elif cvss_score >= 4.0:
                    level = 'medium'
                else:
                    level = 'low'
                    
                self.results['owasp'][level] += 1
                self.results['owasp']['issues'].append({
                    'severity': level,
                    'title': vuln.get('name', 'Unknown vulnerability'),
                    'description': vuln.get('description', ''),
                    'package': dep.get('fileName', ''),
                    'cvss_score': cvss_score,
                    'cve': vuln.get('name', ''),
                    'references': vuln.get('references', [])
                })
    
    def calculate_summary(self):
        """Calculate overall security summary"""
        total_critical = sum(r['critical'] for r in self.results.values())
        total_high = sum(r['high'] for r in self.results.values())
        total_medium = sum(r['medium'] for r in self.results.values())
        total_low = sum(r['low'] for r in self.results.values())
        
        if total_critical > 0:
            status = 'CRITICAL'
        elif total_high > 0:
            status = 'HIGH RISK'
        elif total_medium > 0:
            status = 'MEDIUM RISK'
        elif total_low > 0:
            status = 'LOW RISK'
        else:
            status = 'SECURE'
            
        return {
            'critical_count': total_critical,
            'high_count': total_high,
            'medium_count': total_medium,
            'low_count': total_low,
            'total_count': total_critical + total_high + total_medium + total_low,
            'overall_status': status,
            'timestamp': datetime.now().isoformat(),
            **self.results
        }
    
    def generate_html_report(self, output_file):
        """Generate HTML security report"""
        template_str = """
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Security Scan Report - GreenLink Capital</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; background-color: #f5f5f5; }
        .container { max-width: 1200px; margin: 0 auto; background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
        .header { text-align: center; border-bottom: 2px solid #333; padding-bottom: 20px; margin-bottom: 30px; }
        .summary { display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 20px; margin-bottom: 30px; }
        .metric-card { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 8px; text-align: center; }
        .metric-card.critical { background: linear-gradient(135deg, #ff6b6b 0%, #ee5a52 100%); }
        .metric-card.high { background: linear-gradient(135deg, #ffa726 0%, #ff9800 100%); }
        .metric-card.medium { background: linear-gradient(135deg, #ffee58 0%, #fdd835 100%); color: #333; }
        .metric-card.low { background: linear-gradient(135deg, #66bb6a 0%, #4caf50 100%); }
        .metric-number { font-size: 2.5em; font-weight: bold; margin-bottom: 5px; }
        .metric-label { font-size: 0.9em; opacity: 0.9; }
        .scanner-section { margin-bottom: 40px; }
        .scanner-title { color: #333; border-bottom: 1px solid #ddd; padding-bottom: 10px; margin-bottom: 20px; }
        .issue-card { background: #f9f9f9; border-left: 4px solid #ddd; padding: 15px; margin-bottom: 15px; border-radius: 4px; }
        .issue-card.critical { border-left-color: #f44336; }
        .issue-card.high { border-left-color: #ff9800; }
        .issue-card.medium { border-left-color: #ffeb3b; }
        .issue-card.low { border-left-color: #4caf50; }
        .issue-title { font-weight: bold; color: #333; margin-bottom: 8px; }
        .issue-details { color: #666; font-size: 0.9em; }
        .no-issues { text-align: center; color: #666; font-style: italic; padding: 40px; }
        .status-badge { display: inline-block; padding: 5px 15px; border-radius: 20px; font-weight: bold; text-transform: uppercase; }
        .status-critical { background-color: #f44336; color: white; }
        .status-high { background-color: #ff9800; color: white; }
        .status-medium { background-color: #ffeb3b; color: #333; }
        .status-low { background-color: #4caf50; color: white; }
        .status-secure { background-color: #2196f3; color: white; }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ”’ Security Scan Report</h1>
            <p><strong>GreenLink Capital Platform</strong></p>
            <p>Generated: {{ summary.timestamp }}</p>
            <p>Overall Status: <span class="status-badge status-{{ summary.overall_status.lower().replace(' ', '-') }}">{{ summary.overall_status }}</span></p>
        </div>
        
        <div class="summary">
            <div class="metric-card critical">
                <div class="metric-number">{{ summary.critical_count }}</div>
                <div class="metric-label">Critical Issues</div>
            </div>
            <div class="metric-card high">
                <div class="metric-number">{{ summary.high_count }}</div>
                <div class="metric-label">High Risk Issues</div>
            </div>
            <div class="metric-card medium">
                <div class="metric-number">{{ summary.medium_count }}</div>
                <div class="metric-label">Medium Risk Issues</div>
            </div>
            <div class="metric-card low">
                <div class="metric-number">{{ summary.low_count }}</div>
                <div class="metric-label">Low Risk Issues</div>
            </div>
        </div>
        
        {% for scanner_name, scanner_data in summary.items() %}
        {% if scanner_name not in ['critical_count', 'high_count', 'medium_count', 'low_count', 'total_count', 'overall_status', 'timestamp'] %}
        <div class="scanner-section">
            <h2 class="scanner-title">
                {% if scanner_name == 'bandit' %}ğŸ Bandit (Python Security)
                {% elif scanner_name == 'snyk' %}ğŸ“¦ Snyk (Node.js Dependencies)
                {% elif scanner_name == 'snyk_python' %}ğŸ Snyk (Python Dependencies)
                {% elif scanner_name == 'owasp' %}ğŸ›¡ï¸ OWASP Dependency Check
                {% elif scanner_name == 'trivy' %}ğŸ³ Trivy (Container Security)
                {% else %}{{ scanner_name.title() }}
                {% endif %}
                - {{ scanner_data.critical + scanner_data.high + scanner_data.medium + scanner_data.low }} issues found
            </h2>
            
            {% if scanner_data.issues %}
                {% for issue in scanner_data.issues %}
                <div class="issue-card {{ issue.severity }}">
                    <div class="issue-title">
                        <span class="status-badge status-{{ issue.severity }}">{{ issue.severity.upper() }}</span>
                        {{ issue.title }}
                    </div>
                    <div class="issue-details">
                        {% if issue.description %}
                        <p><strong>Description:</strong> {{ issue.description }}</p>
                        {% endif %}
                        {% if issue.file %}
                        <p><strong>File:</strong> {{ issue.file }}{% if issue.line %}:{{ issue.line }}{% endif %}</p>
                        {% endif %}
                        {% if issue.package %}
                        <p><strong>Package:</strong> {{ issue.package }}{% if issue.version %} ({{ issue.version }}){% endif %}</p>
                        {% endif %}
                        {% if issue.cve %}
                        <p><strong>CVE:</strong> 
                        {% if issue.cve is string %}{{ issue.cve }}
                        {% else %}{{ ', '.join(issue.cve) }}
                        {% endif %}
                        </p>
                        {% endif %}
                        {% if issue.cvss_score %}
                        <p><strong>CVSS Score:</strong> {{ issue.cvss_score }}</p>
                        {% endif %}
                    </div>
                </div>
                {% endfor %}
            {% else %}
                <div class="no-issues">
                    âœ… No security issues found by this scanner
                </div>
            {% endif %}
        </div>
        {% endif %}
        {% endfor %}
        
        <div style="text-align: center; margin-top: 40px; padding-top: 20px; border-top: 1px solid #ddd; color: #666;">
            <p>This report was generated automatically by the GreenLink Capital CI/CD security pipeline.</p>
            <p>For questions or concerns, please contact the security team.</p>
        </div>
    </div>
</body>
</html>
        """
        
        template = Template(template_str)
        summary = self.calculate_summary()
        
        html_content = template.render(summary=summary)
        
        with open(output_file, 'w') as f:
            f.write(html_content)
            
        # Also save JSON summary for CI processing
        with open('security-summary.json', 'w') as f:
            json.dump(summary, f, indent=2)
            
        print(f"Security report generated: {output_file}")
        print(f"Summary JSON saved: security-summary.json")
        
        return summary

def main():
    parser = argparse.ArgumentParser(description='Generate consolidated security report')
    parser.add_argument('--bandit-report', help='Path to Bandit JSON report')
    parser.add_argument('--snyk-report', help='Path to Snyk Node.js JSON report')
    parser.add_argument('--snyk-python-report', help='Path to Snyk Python JSON report')
    parser.add_argument('--owasp-report', help='Path to OWASP report directory')
    parser.add_argument('--output', default='security-report.html', help='Output HTML file')
    
    args = parser.parse_args()
    
    generator = SecurityReportGenerator()
    
    if args.bandit_report:
        generator.parse_bandit_report(args.bandit_report)
        
    if args.snyk_report:
        generator.parse_snyk_report(args.snyk_report, 'snyk')
        
    if args.snyk_python_report:
        generator.parse_snyk_report(args.snyk_python_report, 'snyk_python')
        
    if args.owasp_report:
        generator.parse_owasp_report(args.owasp_report)
        
    summary = generator.generate_html_report(args.output)
    
    # Print summary to console
    print("\nğŸ”’ Security Scan Summary:")
    print(f"   Critical: {summary['critical_count']}")
    print(f"   High: {summary['high_count']}")
    print(f"   Medium: {summary['medium_count']}")
    print(f"   Low: {summary['low_count']}")
    print(f"   Status: {summary['overall_status']}")

if __name__ == '__main__':
    main()
```

#### å®‰å…¨é˜ˆå€¼æ£€æŸ¥è„šæœ¬ (`scripts/check-security-thresholds.py`)
```python
#!/usr/bin/env python3
import json
import argparse
import sys

def check_security_thresholds(summary_file, max_critical=0, max_high=5, max_medium=20):
    """Check if security scan results meet defined thresholds"""
    
    try:
        with open(summary_file, 'r') as f:
            summary = json.load(f)
    except FileNotFoundError:
        print(f"âŒ Security summary file not found: {summary_file}")
        sys.exit(1)
    except json.JSONDecodeError:
        print(f"âŒ Invalid JSON in security summary file: {summary_file}")
        sys.exit(1)
    
    critical_count = summary.get('critical_count', 0)
    high_count = summary.get('high_count', 0)
    medium_count = summary.get('medium_count', 0)
    
    failures = []
    
    # Check thresholds
    if critical_count > max_critical:
        failures.append(f"Critical vulnerabilities: {critical_count} (max allowed: {max_critical})")
    
    if high_count > max_high:
        failures.append(f"High-risk vulnerabilities: {high_count} (max allowed: {max_high})")
    
    if medium_count > max_medium:
        failures.append(f"Medium-risk vulnerabilities: {medium_count} (max allowed: {max_medium})")
    
    if failures:
        print("âŒ Security threshold check FAILED:")
        for failure in failures:
            print(f"   â€¢ {failure}")
        print(f"\nOverall status: {summary.get('overall_status', 'UNKNOWN')}")
        print("Please review and address security vulnerabilities before merging.")
        sys.exit(1)
    else:
        print("âœ… Security threshold check PASSED:")
        print(f"   â€¢ Critical: {critical_count}/{max_critical}")
        print(f"   â€¢ High: {high_count}/{max_high}")
        print(f"   â€¢ Medium: {medium_count}/{max_medium}")
        print(f"   â€¢ Status: {summary.get('overall_status', 'SECURE')}")

def main():
    parser = argparse.ArgumentParser(description='Check security thresholds')
    parser.add_argument('--report', required=True, help='Path to security summary JSON file')
    parser.add_argument('--max-critical', type=int, default=0, help='Maximum allowed critical vulnerabilities')
    parser.add_argument('--max-high', type=int, default=5, help='Maximum allowed high-risk vulnerabilities')
    parser.add_argument('--max-medium', type=int, default=20, help='Maximum allowed medium-risk vulnerabilities')
    
    args = parser.parse_args()
    
    check_security_thresholds(
        args.report,
        args.max_critical,
        args.max_high,
        args.max_medium
    )

if __name__ == '__main__':
    main()
```

---

## ğŸ“‹ æ€»ç»“ä¸å®æ–½æŒ‡å—

### å®æ–½ä¼˜å…ˆçº§
1. **P0 - ç«‹å³å®æ–½** (ç¬¬1-2å‘¨)
   - ä»£ç å®¡æŸ¥æµç¨‹å’ŒPRæ¨¡æ¿
   - åŸºç¡€CI/CDæµ‹è¯•æµæ°´çº¿
   - å…³é”®å®‰å…¨æ‰«æ (CodeQL, Snyk)

2. **P1 - çŸ­æœŸå®æ–½** (ç¬¬3-4å‘¨)
   - å®Œæ•´æµ‹è¯•è¦†ç›–ç‡é…ç½®
   - Lighthouseæ€§èƒ½ç›‘æ§
   - å®Œæ•´å®‰å…¨æ‰«æå¥—ä»¶

3. **P2 - ä¸­æœŸå®Œå–„** (ç¬¬2ä¸ªæœˆ)
   - æ€§èƒ½åŸºå‡†è‡ªåŠ¨åŒ–
   - é«˜çº§å®‰å…¨æŠ¥å‘Š
   - å›¢é˜ŸåŸ¹è®­å’Œæ–‡æ¡£å®Œå–„

### æˆåŠŸæŒ‡æ ‡
- **ä»£ç è´¨é‡**: PRåˆå¹¶æ—¶é—´ç¼©çŸ­50%ï¼Œç¼ºé™·ç‡é™ä½80%
- **æµ‹è¯•è¦†ç›–**: è‡ªåŠ¨åŒ–æµ‹è¯•è¦†ç›–ç‡è¾¾åˆ°80%+ï¼ŒE2Eæµ‹è¯•è¦†ç›–å…³é”®ç”¨æˆ·æµç¨‹
- **æ€§èƒ½ä¿è¯**: Core Web Vitalsä¿æŒç»¿è‰²ï¼ŒAPIå“åº”æ—¶é—´<200ms
- **å®‰å…¨é˜²æŠ¤**: é›¶é«˜å±æ¼æ´è¿›å…¥ç”Ÿäº§ç¯å¢ƒï¼Œå®‰å…¨æ‰«æ100%è¦†ç›–

### å›¢é˜Ÿé‡‡ç”¨ç­–ç•¥
1. **æ¸è¿›å¼å¼•å…¥**: ä»æœ€å…³é”®çš„æµç¨‹å¼€å§‹ï¼Œé€æ­¥æ‰©å±•
2. **å·¥å…·é›†æˆ**: ä¸ç°æœ‰å¼€å‘å·¥å…·æ·±åº¦é›†æˆï¼Œå‡å°‘é¢å¤–è´Ÿæ‹…
3. **æŒç»­åŸ¹è®­**: å®šæœŸå®‰å…¨å’Œè´¨é‡æ„è¯†åŸ¹è®­
4. **æŒ‡æ ‡é©±åŠ¨**: å»ºç«‹æ¸…æ™°çš„è´¨é‡æŒ‡æ ‡å’Œæ”¹è¿›ç›®æ ‡

é€šè¿‡æœ¬å·¥ç¨‹è´¨é‡æ‰‹å†Œçš„å…¨é¢å®æ–½ï¼ŒGreenLink Capitalå°†å»ºç«‹èµ·**ä¸–ç•Œçº§çš„è½¯ä»¶å·¥ç¨‹è´¨é‡ä¿è¯ä½“ç³»**ï¼Œç¡®ä¿ä»£ç å®‰å…¨ã€æ€§èƒ½å“è¶Šã€è´¨é‡å¯é ã€‚